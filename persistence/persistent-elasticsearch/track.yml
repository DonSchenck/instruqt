challenges:
- assignment: '- You have been auto logged in as ```

    admin` user, verify by running `oc whoami

    ``` on the command line.


    > You can click on the above command (and all others in this scenario) to automatically
    copy it into the terminal and execute it.


    - Create a new project, that we will use throughout this scenario and create a
    PersistentVolumeClaim on ODF storage class which will be used by Elasticsearch
    pod to persist data


    ```

    oc create -f 1_create_ns_ocs_pvc.yaml

    ```


    ```

    oc project e-library

    ```


    - To verify get the Storage Class (SC) and PersistentVolumeClaim (PVC)


    ```

    oc get pvc

    ```


    ```

    oc get sc

    ```


    - With just a few lines of YAML, you have created a PVC named `ocs-pv-claim` on
    storage class `ocs-storagecluster-ceph-rbd` which is provisioned from OpenShift
    Container Storage. Elasticsearch needs persistence for its data and OpenShift
    Container Storage is one of the simplest and reliable option that you can choose
    to persist data for you apps running on OpenShift Container Platform.

    - Let''s continue to the next section to deploy the Elasticsearch cluster.

    '
  difficulty: basic
  notes:
  - contents: "# What is OpenShift Container Storage (ODF)\n\nRed Hat\xAE OpenShift\xAE\
      \ Container Storage is software-defined storage for containers. Engineered as\
      \ the data and storage services platform for Red Hat OpenShift, Red Hat OpenShift\
      \ Container Storage helps teams develop and deploy applications quickly and\
      \ efficiently across clouds.\n\n# What will you learn\n\nIn this tutorial you\
      \ will learn how to create Persistent Volumes and use that for deploying Elasticsearch.\
      \ You will then deploy a demo app which is a e-library search engin for 100\
      \ classic novels. Once the app is successfully deployed, you could search any\
      \ word from 100 classic novels, the search is powered by Elasticsearch which\
      \ is using persistent storage from ODF. The logical architecture of the app\
      \ that you will deploy looks like this\n\n![alt text](https://github.com/mulbc/learn-katacoda/raw/master/persistence/persistent-elasticsearch/architecture.png)\n"
    type: text
  slug: '01'
  tabs:
  - hostname: crc
    title: CLI
    type: terminal
  - hostname: crc
    path: /
    port: 30001
    title: Web Console
    type: service
  - hostname: crc
    path: /root
    title: Visual Editor
    type: code
  timelimit: 225
  title: Create Project and PVC
  type: challenge
- assignment: "- Apply the YAML file to deploy Elasticsearch\n\n```\noc create -f\
    \ 2_deploy_elasticsearch.yaml\n```\n\n- To make Elasticsearch persistent we have\
    \ defined ODF PVC under `volumes` section, mounted it under `volumeMounts` inside\
    \ the deployment manifest file, as shown below. Doing this, Elasticsearch will\
    \ then store all of its data on the the PersistentVolumeClaim which resides on\
    \ OpenShift Container Storage.\n\n```\n...\n    spec:\n      volumes:\n      \
    \  - name: ocs-pv-storage\n          persistentVolumeClaim:\n            claimName:\
    \ ocs-pv-claim\n...\n...\n...\n        volumeMounts:\n          - mountPath: \"\
    /usr/share/elasticsearch/data\"\n            name: ocs-pv-storage\n```\n\n> As\
    \ a developer, this should be the most important stage to enable data persistence\
    \ for your application. When you request PVC that are provisioned via ODF storage\
    \ class, the OpenShift Container Storage subsystem make sure your application's\
    \ data is persistent and reliably stored.\n"
  difficulty: basic
  slug: '02'
  tabs:
  - hostname: crc
    title: CLI
    type: terminal
  - hostname: crc
    path: /
    port: 30001
    title: Web Console
    type: service
  - hostname: crc
    path: /root
    title: Visual Editor
    type: code
  timelimit: 225
  title: Deploy Elasticsearch on ODF
  type: challenge
- assignment: "- Apply the YAML file to deploy application's backend API\n\n```\n\
    oc create -f 3_deploy_backend_api.yaml\n```\n\n- In order for the frontend app\
    \ to reach the backend API, set ``BACKEND_URL`` environment variable as a config\
    \ map, by executing the following commands\n\n```\necho \"env = {BACKEND_URL:\
    \ 'http://$(oc get route -n e-library -o=jsonpath=\"{.items[0]['spec.host']}\"\
    )'}\" > env.js\n```\n\n```\noc create configmap -n e-library env.js --from-file=env.js\n\
    ```\n\n- Finally deploy the frontend application\n\n```\noc create -f 4_deploy_frontend_app.yaml\n\
    ```\n\nAt this point our frontend and backend applications are deployed and are\
    \ configured to use Elasticsearch\n\n- To verify execute the following commands.\
    \ \n\n```\noc get po,svc,route \n```\n\n- Before you move to next step, please\
    \ make sure all the pods are in ``Running`` state. If they are not, then please\
    \ allow a few minutes.\n  \n```\noc get po,svc,route \n```"
  difficulty: basic
  slug: '03'
  tabs:
  - hostname: crc
    title: CLI
    type: terminal
  - hostname: crc
    path: /
    port: 30001
    title: Web Console
    type: service
  - hostname: crc
    path: /root
    title: Visual Editor
    type: code
  timelimit: 225
  title: Deploy app backend & frontend
  type: challenge
- assignment: '- Let''s load the text formatted dataset of 100 classic novels from
    the Gutenberg''s collection into our Elasticsearch service.


    > Note : Hang Tight ! The data ingestion could take a few minutes.


    ```

    oc exec -it e-library-backend-api -n e-library -- curl -X POST http://localhost:3000/load_data

    ```


    > Here the ingested data is getting stored on Elasticsearch shards which are in-turn
    using ODF PVC for persistence.


    - As soon as the data is ingested, Elasticsearch will index that and make it search-able.

    - Grab the frontend URL and open that in your web-browser to search for any random
    words.

    - _URL_ http://frontend-e-library.[[HOST_SUBDOMAIN]]-80-[[KATACODA_HOST]].environments.katacoda.com


    ```

    oc get route frontend -n e-library

    ```


    - Elasticsearch real-time search capabilities, instantly searches a large dataset.
    Thus making it a popular choice for logging,metrics,full-text search, etc. use
    cases.


    ## Final Thoughts


    Elasticsearch offers replication at per index level to provide some data resilience.
    Additional data resilience can be provided by deploying Elasticsearch on top of
    a reliable storage service layer such as OpenShift Container Storage which offers
    further resilience capabilities. This additional data resilience can enhance Elasticsearch
    service availability during broader infrastructure failure scenarios. Because
    of limited system resources available in this lab environment, we could not demonstrate
    the enhanced resiliency capabilities of Elasticsearch when deployed on OpenShift
    Container Storage, but you have got the idea :)


    Happy Persistency \o

    '
  difficulty: basic
  slug: '04'
  tabs:
  - hostname: crc
    title: CLI
    type: terminal
  - hostname: crc
    path: /
    port: 30001
    title: Web Console
    type: service
  - hostname: crc
    path: /root
    title: Visual Editor
    type: code
  timelimit: 225
  title: Ingest dataset to Elasticsearch
  type: challenge
description: "# What is OpenShift Container Storage (ODF)\n\nRed Hat\xAE OpenShift\xAE\
  \ Container Storage is software-defined storage for containers. Engineered as the\
  \ data and storage services platform for Red Hat OpenShift, Red Hat OpenShift Container\
  \ Storage helps teams develop and deploy applications quickly and efficiently across\
  \ clouds.\n\n# What will you learn\n\nIn this tutorial you will learn how to create\
  \ Persistent Volumes and use that for deploying Elasticsearch. You will then deploy\
  \ a demo app which is a e-library search engin for 100 classic novels. Once the\
  \ app is successfully deployed, you could search any word from 100 classic novels,\
  \ the search is powered by Elasticsearch which is using persistent storage from\
  \ ODF. The logical architecture of the app that you will deploy looks like this\n\
  \n![alt text](https://github.com/mulbc/learn-katacoda/raw/master/persistence/persistent-elasticsearch/architecture.png)\n"
developers:
- dahmed@redhat.com
- nvinto@redhat.com
- rjarvine@redhat.com
icon: https://logodix.com/logo/1910931.png
level: beginner
owner: openshift
private: false
published: true
skipping_enabled: false
slug: persistence-persistent-elasticsearch
tags:
- openshift
title: Persistent Storage for Elasticsearch Powered by OpenShift Container Storage
type: track
